{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EMOCHAT\n**Team** <br>\nAmit Krishna A - 19BCE0197 <br>\nSwamitha Gupta - 19BCE0728 <br>\nArush Bhat     - 19BCE0564 <br>\nAgniva Basak   - 19BCE0744\n"},{"metadata":{},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import *\n\nimport pandas as pd\nimport numpy as np\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport PIL\nimport PIL.Image\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\nfrom tqdm import tqdm\nimport cv2\nimport pathlib","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = '../input/fer2013/fer2013.csv'\n\n# This dataset consists of 35887 grayscale, 48x48 sized face images with 7 labeled emotions\n\nlabels = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames=['emotion','pixels','usage']\ndf=pd.read_csv(dataset,names=names, na_filter=False)\nimages=df['pixels']\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Face Detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"def detect_and_crop_faces(img):\n    img = img.astype(\"uint8\")\n    face_cascade = cv2.CascadeClassifier(\"../input/haarcascade-frontalface-default/haarcascade_frontalface_default.xml\")\n    faces = face_cascade.detectMultiScale(img, 1.01, 5)\n    if len(faces) == 0:\n        haar_img = img\n    else:\n        x, y, w, h = faces[0]\n        haar_img = img[y:y+h, x:x+w]\n        \n    return ((haar_img).astype(\"float32\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getData(filname):\n    # images are 48x48\n    # N = 35887\n    Y = []\n    X = []\n    first = True\n    for line in open(filname):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X = np.array(X)\n    Y = np.array(Y)\n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, Y = getData(dataset)\nN, D = X.shape\nimg_X = X.reshape(N, 48, 48, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z = []\nfor img in tqdm(list(img_X)):\n    img_resize = cv2.resize(detect_and_crop_faces(img), (48, 48))\n    Z.append(img_resize)\n    \nX = Z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalization\nX = np.array(Z)\nX = X/255\n\nnum_class = len(set(Y))\nprint(num_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgplot = plt.imshow(X[10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.reshape(N, 48, 48, 1)\nY = (np.arange(num_class) == Y[:, None]).astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"VGG_model = tf.keras.applications.VGG16(include_top=False,weights='imagenet')\nbottleneck_features = np.empty([N, 512])\n\nfor i in tqdm(range(N)):\n    img = np.expand_dims(X[i], axis=0)\n    feature = VGG_model.predict(img)\n    features_flatten = feature.flatten()\n    bottleneck_features[i] = feature.flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"def my_model():\n    model = Sequential()\n    model.add(VGG_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Flatten())\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dense(512, activation='relu'))\n    model.add(Dense(num_class, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    \n    return model\n\nmodel = my_model()\nmodel.summary()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    \n    model.add(Conv2D(64, (5, 5),input_shape = input_shape, activation='relu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    \n    return model\nmodel=my_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_model='model_filter.h5' # save model at this location after each epoch\ntf.keras.backend.clear_session() # destroys the current graph and builds a new one\n\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n\n# fit the model\nh=model.fit(x=X,     \n            y=Y,\n            validation_split = 0.2,\n            batch_size=64, \n            epochs=20, \n            verbose=1,\n            shuffle=True,\n            callbacks=[ModelCheckpoint(filepath=path_model),]\n            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"plt.plot(h.history['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert the model.\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n    f.write(tflite_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\ny_pos = np.arange(len(objects))\nprint(y_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def emotion_analysis(emotions):\n    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n    y_pos = np.arange(len(objects))\n    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import io\n\n\ndef predict_emotion(path):\n    img = image.load_img(path, grayscale=True, target_size=(48, 48))\n    show_img=image.load_img(path, grayscale=False, target_size=(200, 200))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis = 0)\n\n    x /= 255\n\n    custom = model.predict(x)\n    emotion_analysis(custom[0])\n\n    x = np.array(x, 'float32')\n    x = x.reshape([48, 48]);\n\n    plt.gray()\n    plt.imshow(show_img)\n    plt.show()\n\n    m=0.000000000000000000001\n    a=custom[0]\n    for i in range(0,len(a)):\n        if a[i]>m:\n            m=a[i]\n            ind=i\n        \n    print('Expression Prediction:',objects[ind])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_emotion('../input/images/h_image.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_emotion('../input/images/s_image.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}